# -*- coding: utf-8 -*-
"""NanaAfiaPokuaOforiAsante_SportsPrediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hXW_2suthNb525OM4Dxvs3LIP2gZ3czZ
"""

import pandas as pd

from google.colab import drive
drive.mount('/content/drive')

legacy = pd.read_csv('/content/male_players (legacy).csv')

legacy.head()

legacy.info()

import pandas as pd
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import LabelEncoder

def preprocessing(legacy):
    # Checking for missing values
    numeric_columns = legacy.select_dtypes(include=['float64', 'int64'])
    missing_values = numeric_columns.isnull().sum()

    # Replacing missing values with the mean of its columns
    legacy[numeric_columns.columns] = legacy[numeric_columns.columns].fillna(numeric_columns.mean())

    # Dropping specified columns
    columns_to_drop = [
          "player_positions", "league_name", "club_name",
        "dob", "player_url", "long_name", "short_name", "club_team_id",
        "player_face_url", "real_face", "lcm", "cm", "rcm",
        "lf", "rf", "ldm", "cdm", "rdm", "rwb", "lb", "lcb", "cb", "rcb",
        "cf","lw","rw","lam","ram","cam","rm","lm","st","ls","rs","lwb","rb"
    ]
    legacy = legacy.drop(columns=columns_to_drop)

    # Filtering columns based on missing values threshold
    L = []
    L_less = []
    for i in legacy.columns:
        if legacy[i].isnull().sum() < (0.3 * legacy.shape[0]):
            L.append(i)
        else:
            L_less.append(i)

    legacy = legacy[L]

    # Separating numeric and non-numeric features
    numeric_columns = legacy.select_dtypes(exclude=['object']).columns
    non_numeric = legacy.select_dtypes(include=['object']).columns

    cat_data = legacy[non_numeric]
    numeric_data = legacy[numeric_columns]

    # Imputing the numeric data with the median
    imp = SimpleImputer(strategy='median')
    a = imp.fit_transform(numeric_data)
    numeric_data_impute = pd.DataFrame(a, columns=numeric_columns)

    # Filling missing values in categorical data using forward fill
    cat_data_processed = cat_data.fillna(method='ffill')
    cat_data_processed = pd.DataFrame(cat_data_processed, columns=cat_data.columns)

    # Encoding the categorical data
    label_encoders = {}
    for column in cat_data_processed.columns:
        cat_data_processed[column] = cat_data_processed[column].astype(str)
        label_encoders[column] = LabelEncoder()
        cat_data_processed[column] = label_encoders[column].fit_transform(cat_data_processed[column])

    # Joining numeric and processed categorical data
    legacy = pd.concat([numeric_data_impute, cat_data_processed], axis=1)

    return legacy

processed_legacy =  preprocessing(legacy)

processed_legacy

#question 2
corr_matrix = processed_legacy.corr()
corr_overall = corr_matrix['overall'].sort_values(ascending=False)

top_features = 10
features = corr_overall.head(top_features)
print(features)

#question 3
selected_columns=["overall","movement_reactions","mentality_composure","potential","wage_eur","passing","attacking_short_passing","attacking_short_passing","value_eur","dribbling"]
#droping non_selected columns
non_selected_columns = [col for col in processed_legacy.columns if col not in selected_columns]

processed_legacy.drop(non_selected_columns, axis=1, inplace=True)
processed_legacy

#Question 3
#training the model
#x=processed_legacy
#y=processed_legacy['overall']
y = processed_legacy['overall']
processed_legacy = processed_legacy.drop(columns=['overall'])
x = processed_legacy

#scaling x
from sklearn.preprocessing import StandardScaler
#creating an instance of standscaler
scaler=StandardScaler()
scaled=scaler.fit_transform(x)

#splitting the dataset into training and testing sets
from sklearn.model_selection import train_test_split
Xtrain,Xtest,Ytrain,Ytest=train_test_split(x,y,test_size = 0.2,random_state =42)

Xtrain.shape

Xtest.shape

# pickling the model
#creating the scaler model
import pickle
pickle_out = open("scaler.pkl", "wb")
pickle.dump(scaled, pickle_out)
pickle_out.close()

!pip install xgboost

from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.model_selection import cross_val_score
import  xgboost as xgb
from sklearn.metrics import mean_absolute_error
#Random Forest
rf=RandomForestRegressor()
rf.fit(Xtrain,Ytrain)

#gradientboost regressor
grad_boost=GradientBoostingRegressor(max_depth=2,n_estimators=3,learning_rate=1.0)
grad_boost.fit(Xtrain,Ytrain)
#XGBoost
xgb_reg=xgb.XGBRegressor()
xgb_reg.fit(Xtrain,Ytrain)

#Finding the mean score for each model to get each model's performance
#then hyperparameter tune
rf_score=cross_val_score(rf, Xtest, Ytest,cv=5)
print("The Random Forest Regressor score is :", rf_score.mean())

#displaying the gradientboost score
gradb_score=cross_val_score(grad_boost, Xtest, Ytest,cv=5)
print("The Gradient Boosting Regressor score is :", gradb_score.mean())

xgb_reg_score=cross_val_score(rf, Xtest, Ytest,cv=5)
print("The XGBoost Regressor score is :", xgb_reg_score.mean())

#Grid search and cross-validation
#ensemble Random forest regressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import KFold
import  xgboost as xgb
from sklearn.metrics import mean_absolute_error

#Initialize Random Forest Regressor
rf = RandomForestRegressor()
#hyperparameters and their possible values for the grid search
param_grid = {
    'n_estimators': [60, 100, 200],
    'max_depth': [None, 10, 20, 30],
}
#grid search with cross-validation
grid = GridSearchCV(estimator=rf, param_grid=param_grid, cv=KFold(n_splits=5, shuffle=True, random_state=42))

#grid search fit legacy (training data)
grid.fit(Xtrain, Ytrain)

#obtain the best model with the best hyperparameters
best_rf = grid.best_estimator_

# Predicting on the test data using the best model
y_predict = best_rf.predict(Xtest)
mae = mean_absolute_error(Ytest, y_predict)
print("Mean Absolute Error for the Best Random Forest Model:", mae)

#gradientboosting regressor
grad_b = GradientBoostingRegressor()

#grid search with cross- validation for gradientBoosting
grid_grad_boost = GridSearchCV(estimator=grad_b, param_grid=param_grid, cv=KFold(n_splits=5, shuffle=True, random_state=42))
#grid search fit to the training data
grid_grad_boost.fit(Xtrain, Ytrain)

# obtain the best model with the best hyperparameters
best_grad_boost = grid_grad_boost.best_estimator_

#data fitting with the model
best_grad_boost.fit(Xtrain, Ytrain)

# Predicting on the test data
y_predict = best_grad_boost.predict(Xtest)

# Mean Absolute Error (MAE) value
mae = mean_absolute_error(Ytest, y_predict)
print("Mean Absolute Error for the Best Gradient Boosting Model:", mae)

#XGBoost
xgb_reg = xgb.XGBRegressor()
param = {
    'n_estimators': [60, 150, 220],
    'max_depth': [10, 15, 20] ,
    }
#grid search with cross-validation for the XGBoost
grid_xgb = GridSearchCV(estimator=xgb_reg, param_grid=param, cv=KFold(n_splits=5, shuffle=True, random_state=42))

#grid search fit to the training data
grid_xgb.fit(Xtrain, Ytrain)

#obtaining the best model with the best hyperparameters
best_xgb = grid_xgb.best_estimator_

#Fit the best model to the training data
best_xgb.fit(Xtrain, Ytrain)

#Predicting on the test data
y_predict = best_xgb.predict(Xtest)

#Mean Absolute Error (MAE) value
mae = mean_absolute_error(Ytest, y_predict)
print("Mean Absolute Error for the Best XGB Regressor Model:", mae)

from sklearn.ensemble import VotingRegressor
voting_reg = VotingRegressor(estimators=[
    ('RandomForest', best_rf),
    ('GradientBoosting', best_grad_boost),
    ('XGBoost', best_xgb)
])
# Fitting & training data
voting_reg.fit(Xtrain, Ytrain)
# test data predictions using the ensemble model
ensemble_pred= voting_reg.predict(Xtest)

# Evaluating using mean squared error(mse)
from sklearn.metrics import mean_squared_error

# Evaluating using mean absolute error (mae)
mae = mean_absolute_error(ensemble_pred, Ytest)
print("Mean Absolute Error for Ensemble:", mae)

import pickle
pickle_out = open("voting_reg.pkl", "wb")
pickle.dump(voting_reg, pickle_out)
pickle_out.close()

"""Test"""

players_22 = pd.read_csv('/content/players_22-1.csv')

players_22.head()

processed_players_22 =  preprocessing(players_22)

processed_players_22

# test_sub_columns = ["movement_reactions","mentality_composure","potential","wage_eur","passing","attacking_short_passing","value_eur","dribbling"]
# #top feature subsets
# top_feat = players_22[test_sub_columns]
# #display top feat
# top_feat

sc = StandardScaler()
scaled = sc.fit_transform(processed_players_22)
top_feat = pd.DataFrame(scaled,columns = processed_players_22.columns)
top_feat

X_test = top_feat
X_test

